{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasanenesguray/Homework/blob/main/Copy_of_CS412_HW4_2023_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voHKcAfRfdNY"
      },
      "source": [
        "# CS412 - Machine Learninig - 2022-2023\n",
        "## Homework 4 - 100 pts\n",
        "\n",
        "\n",
        "## Goal\n",
        "\n",
        "The goal of this homework is two-fold:\n",
        "\n",
        "*   Introduction to the Transfer Learning\n",
        "*   Gain experience with three dimensional input data (colored images), and pretrained models (Part-A)\n",
        "\n",
        "## Dataset\n",
        "[**CelebA**](https://www.cs.toronto.edu/~kriz/cifar.html) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter.\n",
        "\n",
        "**Download the data from Sucourse and upload it to your Google drive. In your Google drive, you need to have CelebA30k.zip and CelebA30k.csv uploaded. (Do not change the name of these files.) Reserve 10% of the training data for validation and %10 for test** and  **use the rest for development (learning your models). The test data (3000 samples) should only be used for testing at the end, and not model selection.**\n",
        "\n",
        "## Task\n",
        "Build a classifier with the Keras library function calls and pretrained models to *classify gender* in the CelebA dataset, completing the given code and without changing the network.\n",
        "\n",
        "\n",
        "## Software: \n",
        "\n",
        "Keras is a library that we will use especially for deep learning, but also with basic neural network functionality of course. \n",
        "\n",
        "You may find the necessary function references here: \n",
        "\n",
        "http://scikit-learn.org/stable/supervised_learning.html\n",
        "\n",
        "https://keras.io/api/\n",
        "\n",
        "https://keras.io/api/applications/\n",
        "\n",
        "When you search for Conv2d for instance, you should find the relevant function and explained parameters, easily.\n",
        "\n",
        "## Submission: \n",
        "Fill this notebook. Follow the submission/answer requirements in SuCourse. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YOYiWvHbNDW"
      },
      "source": [
        "##1) Initialize\n",
        "\n",
        "*   First make a copy of the notebook given to you as a starter.\n",
        "\n",
        "*   Make sure you choose Connect form upper right.\n",
        "\n",
        "*   Make sure you change your runtime to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM-wwHR8qL0M"
      },
      "source": [
        "## 2) Load training dataset\n",
        "\n",
        "*  Read from Keras library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsX8gEbCUqPr"
      },
      "source": [
        "# load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from numpy import random\n",
        "from PIL import Image\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, Flatten\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1\n",
        "np.random.seed(5)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img,img_to_array,array_to_img,save_img\n",
        "import cv2\n",
        "import os\n",
        "% matplotlib inline"
      ],
      "metadata": {
        "id": "k_uBeZBxiUbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/CS412/Homeworks/celeba_30k.csv') # enter the file path on your drive for the csv file\n",
        "data.head()"
      ],
      "metadata": {
        "id": "EaTfK-gqx_Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_data = data[['image_id', 'Male']].copy()\n",
        "gender_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_qclIO8ME50L",
        "outputId": "81f8f4bc-8f6c-4278-cf68-0eb76567137a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id  Male\n",
              "0  000001.jpg     0\n",
              "1  000002.jpg     0\n",
              "2  000003.jpg     1\n",
              "3  000004.jpg     0\n",
              "4  000005.jpg     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7941048e-ed65-4fb9-8751-080ef598a7ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7941048e-ed65-4fb9-8751-080ef598a7ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7941048e-ed65-4fb9-8751-080ef598a7ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7941048e-ed65-4fb9-8751-080ef598a7ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdL_gFRHfn-6"
      },
      "source": [
        "#this will extract the contents of the zip file into a folder named data\n",
        "#do not extract the zip into your google drive (i.e don't use drive/My Drive in the right path since it slows down the process)\n",
        "#only change the left path\n",
        "\n",
        "!unzip \"/content/drive/My Drive/celeba_30k/celeba_30k.zip\" -d \"/content/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_image_path = os.path.join(\"/content/data/celeba_30k/\", gender_data.loc[0,\"image_id\"])\n",
        "img = Image.open(first_image_path) "
      ],
      "metadata": {
        "id": "jz1C-X1Phq9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "1gTbCFl0fnx_",
        "outputId": "77aa109c-95cc-43d8-9502-f8503002071c"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NdW2ItjHLxJ"
      },
      "source": [
        "##3) Visualizing/Understanding the dataset\n",
        "\n",
        "- Display five random images together with their labels\n",
        "\n",
        "- Display statistics about the dataset, such as distribution of labels, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA_AjGQasjvS"
      },
      "source": [
        "# plot random 5 images in your dataset with their labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vop4rwZVxh9Z"
      },
      "source": [
        "##4) Split the dataset as train (also called development) (80%) and validation (10%) and test (10%) set. You'll tune the hyperparameters using the validation set and evaulate the model on the unseen test set. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gender_data[\"Male\"] = gender_data[\"Male\"].replace({0: 'Female', 1: 'Male'}) "
      ],
      "metadata": {
        "id": "7jit5N1ohyIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEhk8R24xhdY"
      },
      "source": [
        "# Split 80-10-10\n",
        "from sklearn.model_selection import train_test_split \n",
        "train_df, val_df = train_test_split(gender_data, test_size=0.1, random_state=42, shuffle = True)\n",
        "train_df, test_df = train_test_split(train_df, test_size=1/9, random_state=42, shuffle = True) #since 0.9 * (1/9) = 0.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/data/celeba_30k\" #where you extracted the zip file\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = val_df.shape[0]\n",
        "batch_size=...\n",
        "\n",
        "#create the test_generator accordingly\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator() #augmentations for training set... https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    data_path, \n",
        "    x_col='image_id',\n",
        "    y_col='Male',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224,224), #this will resize the image, you can change the size\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "val_datagen = ImageDataGenerator() #augmentations for validation set\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df, \n",
        "    data_path, \n",
        "    x_col='image_id',\n",
        "    y_col='Male',\n",
        "    target_size=(224,224),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "V02S13WNAn2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5) Transfer Learning with VGG-16\n",
        "\n",
        "We will create the base model from the well-known VGG-16 model. This is pre-trained on ImageNet dataset, a large dataset consisting of 1.4M images and 1000 classes.\n",
        "\n",
        "First, you need to pick which layer of VGG-16 you will use for feature extraction. The very last classification layer (called \"top\", as most diagrams of machine learning models go from bottom to top) is not very useful. Instead, you will follow the common practice to depend on the very last layer before the flatten operation. This layer is called the \"bottleneck layer\". The bottleneck layer features retain more generality as compared to the final/top layer.\n",
        "\n",
        "You'll also load the pretrained weights from ImageNet by specifying weights='imagenet'. \n"
      ],
      "metadata": {
        "id": "eGqTsEANb0kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(weights='imagenet', input_shape = (224,224,3), include_top=False)\n",
        "base_model.summary()\n"
      ],
      "metadata": {
        "id": "yPNmpem-A0dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting the trainable attribute to False, we ensure that the original (ImageNet) weights of the model will remain constant.\n",
        "\n",
        "Note that it is possible to adjust the number of trainable layers by modifying the for loop."
      ],
      "metadata": {
        "id": "0cBj1jprmRKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#By setting the trainable attribute to False, we ensure that the original (ImageNet) weights of the model will remain constant.\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "sPxREGOvA5yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a binary classifier (Male/Female) which we will add manually on top of the pre-trained model. This layer is usually called \"classification head\". \n"
      ],
      "metadata": {
        "id": "XgTV9JXClM41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_model(base_model, img_shape = (224,224,3)):\n",
        "    \n",
        "    \n",
        "    # create the input layer (Same as the imageNetv2 input size)\n",
        "    inputs = tf.keras.Input(shape=img_shape) \n",
        "    \n",
        "    # Forward pass to get the output of the last pooling layer\n",
        "    X = base_model(inputs)\n",
        "\n",
        "    #Flatten the output\n",
        "    X = ...\n",
        "    \n",
        "    # Define the new binary classification head \n",
        "    \n",
        "    X = ...\n",
        "        \n",
        "    outputs = ...\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "4PjONZLyA9s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-) Fine-Tuning the Model\n",
        "\n",
        "Since our base model is trained on a different dataset (ImageNet), we still need to tune the hyperparameters. \n",
        "Tune learning rate (most important), number of epochs and batch size."
      ],
      "metadata": {
        "id": "Zyvuf_ocssQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with generators fit method should be used like below:\n",
        "# optimizer could be SGD from tf.keras.optimizers or something else if you wish to experiment\n",
        "# loss could be Binary cross entropy from tf.keras.losses\n",
        "model.compile(optimizer=...),\n",
        "              loss=...,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_generator, batch_size=...,\n",
        "                              epochs=..., validation_data = val_generator, workers = 8) #workers loads the data in parallel\n"
      ],
      "metadata": {
        "id": "0exXbzyUA_8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Train the Network with  Tuned Parameters"
      ],
      "metadata": {
        "id": "VudyisrdvdtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model with the tuned parameters\n",
        "#You can also use methods like early stopping based on validation loss to counter overfitting, reducing the learning rate on plateau etc.\n",
        "#Keep the batch size small (i.e 8 or 16) if you get a memory error\n",
        "\n",
        "\n",
        "#https://keras.io/api/callbacks/early_stopping/\n",
        "#https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
        " \n",
        "#model.compile(loss=..., optimizer=..., metrics=['accuracy'])\n",
        "#history = model.fit(...)\n",
        "\n",
        "#You can plot training/validation loss using history\n",
        "\n",
        "# Report your results\n",
        "\n",
        "#...\n",
        "\n"
      ],
      "metadata": {
        "id": "-zX3O4XpBDHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boqe46St1--f"
      },
      "source": [
        "## 8) Test your classifier on Test set\n",
        "\n",
        "- Predict the labels of testing data **using the best model that you have selected according to your validation results** and report the accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLke8jyFGng"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Load test data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Report your result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}